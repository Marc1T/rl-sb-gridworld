# evaluation/evaluate_model_v2.py
import sys
import os
import time

# --- Configuration du chemin du projet ---
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.append(project_root)

import numpy as np
from stable_baselines3 import PPO
from envs.gridworld_env_v2 import GridWorldEnv
from utils.config import config


def evaluate_model_v2(model_path: str, n_episodes: int = 5, render: bool = True):
    """
    Ã‰value un modÃ¨le PPO sur GridWorldEnv_v2.
    Visualise (optionnellement) le comportement et affiche les scores moyens.
    """
    print(f"\nðŸš€ Ã‰valuation du modÃ¨le : {model_path}")
    env = GridWorldEnv(grid_size=config["env"]["size"], render_mode="human" if render else None)
    model = PPO.load(model_path)

    rewards = []
    steps_per_episode = []

    for episode in range(1, n_episodes + 1):
        obs, _ = env.reset()
        done = False
        total_reward = 0
        step_count = 0

        while not done:
            # PrÃ©dire lâ€™action depuis lâ€™observation
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated
            total_reward += reward
            step_count += 1

            if render:
                env.render()
                time.sleep(0.2)  # ralentir pour mieux visualiser

        rewards.append(total_reward)
        steps_per_episode.append(step_count)
        print(f"ðŸŽ¯ Ã‰pisode {episode}: Reward total = {total_reward:.2f}, Ã©tapes = {step_count}")

    env.close()

    # Statistiques globales
    print("\nðŸ“Š RÃ©sumÃ© de l'Ã©valuation :")
    print(f"â†’ Moyenne des rÃ©compenses : {np.mean(rewards):.2f}")
    print(f"â†’ RÃ©compense min/max : {np.min(rewards):.2f} / {np.max(rewards):.2f}")
    print(f"â†’ Moyenne des Ã©tapes par Ã©pisode : {np.mean(steps_per_episode):.1f}")

    print("\nâœ… Ã‰valuation terminÃ©e.")


if __name__ == "__main__":
    model_file = "ppo_gridworld_v2.zip"  # fichier du modÃ¨le sauvegardÃ©
    evaluate_model_v2(model_file, n_episodes=5, render=True)
